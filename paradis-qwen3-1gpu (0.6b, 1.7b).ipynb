{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup environment","metadata":{}},{"cell_type":"markdown","source":"## Environment variables","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Only use 1 GPU\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:37:44.546386Z","iopub.execute_input":"2025-06-21T05:37:44.546733Z","iopub.status.idle":"2025-06-21T05:37:44.553116Z","shell.execute_reply.started":"2025-06-21T05:37:44.546711Z","shell.execute_reply":"2025-06-21T05:37:44.552289Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Get secrets","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nWANDB_API_KEY = user_secrets.get_secret(\"WANDB_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:37:44.554305Z","iopub.execute_input":"2025-06-21T05:37:44.554570Z","iopub.status.idle":"2025-06-21T05:37:44.839575Z","shell.execute_reply.started":"2025-06-21T05:37:44.554549Z","shell.execute_reply":"2025-06-21T05:37:44.839071Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"!pip install -qU transformers accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:37:44.840169Z","iopub.execute_input":"2025-06-21T05:37:44.840356Z","iopub.status.idle":"2025-06-21T05:39:28.206461Z","shell.execute_reply.started":"2025-06-21T05:37:44.840341Z","shell.execute_reply":"2025-06-21T05:39:28.205785Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    get_linear_schedule_with_warmup\n)\nfrom datasets import load_dataset\n\nimport wandb\nimport numpy as np\nfrom datetime import datetime\nimport json\nfrom tqdm.auto import tqdm\nimport gc\nimport math\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:28.208313Z","iopub.execute_input":"2025-06-21T05:39:28.208549Z","iopub.status.idle":"2025-06-21T05:39:42.273106Z","shell.execute_reply.started":"2025-06-21T05:39:28.208526Z","shell.execute_reply":"2025-06-21T05:39:42.272524Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Random seed & device","metadata":{}},{"cell_type":"code","source":"# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Check GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:42.273896Z","iopub.execute_input":"2025-06-21T05:39:42.274435Z","iopub.status.idle":"2025-06-21T05:39:42.359083Z","shell.execute_reply.started":"2025-06-21T05:39:42.274410Z","shell.execute_reply":"2025-06-21T05:39:42.358466Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Finetune config","metadata":{}},{"cell_type":"code","source":"class Config:\n    # Model configuration\n    model_name = \"Qwen/Qwen3-0.6B\"\n    # model_name = \"Qwen/Qwen3-1.7B\"\n    dataset_name = \"vietgpt/wikipedia_vi\"\n    \n    # Training configuration\n    output_dir = \"./qwen-vietnamese-wiki-finetuned\"\n    # output_dir = \"./qwen-vietnamese-wiki-finetuned-2\"\n    num_train_epochs = 3\n    per_device_train_batch_size = 2\n    per_device_valid_batch_size = 2\n    gradient_accumulation_steps = 8\n    learning_rate = 5e-5\n    weight_decay = 0.01\n    warmup_ratio = 0.1\n    max_length = 128\n\n    # Optimization settings\n    adam_epsilon = 1e-8\n    max_grad_norm = 1.0\n    \n    # Logging and saving\n    logging_steps = 40\n    save_strategy = \"epoch\"\n    valid_strategy = \"epoch\"\n    \n    # Other settings\n    fp16 = True\n    num_workers = os.cpu_count()\n    \n    # W&B configuration\n    use_wandb = True\n    wandb_run_id = None\n    wandb_project = \"PARADIS-Qwen3_0.6B\"\n    # wandb_project = \"PARADIS-Qwen3_1.7B\"\n    wandb_run_name = \"1GPU\"\n\n    # HuggingFace configuration\n    use_hf = True\n    hf_repo = \"Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU\"\n    # hf_repo = \"h9art/PARADIS-Qwen3_1.7B-10kWikiVi-1GPU\"\n    \n    # Dataset\n    train_size = 10000\n    valid_size = 10000\n    test_size = 5000\n    min_text_length = 50\n    random_seed = 42\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:42.359809Z","iopub.execute_input":"2025-06-21T05:39:42.360056Z","iopub.status.idle":"2025-06-21T05:39:42.365578Z","shell.execute_reply.started":"2025-06-21T05:39:42.360027Z","shell.execute_reply":"2025-06-21T05:39:42.364840Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"config_dict = {k: v for k, v in Config.__dict__.items() if not k.startswith(\"__\") and not callable(v)}\nconfig_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:42.366282Z","iopub.execute_input":"2025-06-21T05:39:42.366447Z","iopub.status.idle":"2025-06-21T05:39:42.391060Z","shell.execute_reply.started":"2025-06-21T05:39:42.366434Z","shell.execute_reply":"2025-06-21T05:39:42.390529Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'model_name': 'Qwen/Qwen3-0.6B',\n 'dataset_name': 'vietgpt/wikipedia_vi',\n 'output_dir': './qwen-vietnamese-wiki-finetuned',\n 'num_train_epochs': 3,\n 'per_device_train_batch_size': 2,\n 'per_device_valid_batch_size': 2,\n 'gradient_accumulation_steps': 8,\n 'learning_rate': 5e-05,\n 'weight_decay': 0.01,\n 'warmup_ratio': 0.1,\n 'max_length': 128,\n 'adam_epsilon': 1e-08,\n 'max_grad_norm': 1.0,\n 'logging_steps': 40,\n 'save_strategy': 'epoch',\n 'valid_strategy': 'epoch',\n 'fp16': True,\n 'num_workers': 4,\n 'use_wandb': True,\n 'wandb_run_id': None,\n 'wandb_project': 'PARADIS-Qwen3_0.6B',\n 'wandb_run_name': '1GPU',\n 'use_hf': True,\n 'hf_repo': 'Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU',\n 'train_size': 10000,\n 'valid_size': 10000,\n 'test_size': 5000,\n 'min_text_length': 50,\n 'random_seed': 42}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Setup wandb","metadata":{}},{"cell_type":"code","source":"wandb.login(key=WANDB_API_KEY)\nif config.use_wandb:\n    if config.wandb_run_id is None:\n        wandb.init( # New run\n            project=config.wandb_project,\n            name=config.wandb_run_name,\n            config=config_dict,\n        )\n    else:\n        wandb.init( # Resume to created run\n            project=config.wandb_project,\n            id=config.wandb_run_id,\n            resume='allow',\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:42.391899Z","iopub.execute_input":"2025-06-21T05:39:42.392115Z","iopub.status.idle":"2025-06-21T05:39:54.492293Z","shell.execute_reply.started":"2025-06-21T05:39:42.392098Z","shell.execute_reply":"2025-06-21T05:39:54.491530Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtungnguyen19995969\u001b[0m (\u001b[33mtungnguyen19995969-hanoi-university-of-science-and-techn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250621_053948-j6f85ssx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B/runs/j6f85ssx' target=\"_blank\">1GPU</a></strong> to <a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B' target=\"_blank\">https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B/runs/j6f85ssx' target=\"_blank\">https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B/runs/j6f85ssx</a>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Setup HuggingFace","metadata":{}},{"cell_type":"code","source":"if config.use_hf:\n    from huggingface_hub import login, HfApi\n    login(HF_TOKEN)\n    hf_api = HfApi()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:54.493181Z","iopub.execute_input":"2025-06-21T05:39:54.493453Z","iopub.status.idle":"2025-06-21T05:39:54.589927Z","shell.execute_reply.started":"2025-06-21T05:39:54.493431Z","shell.execute_reply":"2025-06-21T05:39:54.589235Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Model and tokenizer","metadata":{}},{"cell_type":"markdown","source":"## Download and quantization","metadata":{}},{"cell_type":"code","source":"print(\"Loading tokenizer and model...\")\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    config.model_name,\n    trust_remote_code=True,\n    padding_side=\"right\"\n)\n\n# Add pad token if it doesn't exist\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Cấu hình 4-bit quantization\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.model_name,\n    device_map=\"auto\", # automatically move to correct device\n    quantization_config=quantization_config,\n    torch_dtype=torch.float32,\n    trust_remote_code=True\n)\n\n# Turn on gradient checkpointing to save memory\nmodel.config.use_cache = False\nmodel.gradient_checkpointing_enable()\n\n# Num parameters\nprint(f\"Model loaded. Parameters: {model.num_parameters():,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:39:54.592504Z","iopub.execute_input":"2025-06-21T05:39:54.592732Z","iopub.status.idle":"2025-06-21T05:40:31.727902Z","shell.execute_reply.started":"2025-06-21T05:39:54.592715Z","shell.execute_reply":"2025-06-21T05:40:31.727179Z"}},"outputs":[{"name":"stdout","text":"Loading tokenizer and model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f423c191526c45e1a0eec40f22a07500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076dcbbd6cfe4262af29cc0f360fc576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86352e88873e41fd93d0fde3f7ecae54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c4c4a1964c94214b1c62df9d9260e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2ad694efa9490d8728a60f33014bfb"}},"metadata":{}},{"name":"stderr","text":"2025-06-21 05:40:05.330717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750484405.750920      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750484405.860071      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b7d17f80834afcb457212d24b3758b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fe8ab41e4c1461ca3e4babfda2fc108"}},"metadata":{}},{"name":"stdout","text":"Model loaded. Parameters: 596,049,920\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Generation function","metadata":{}},{"cell_type":"code","source":"def generate_text(\n    prompt,\n    max_length=config.max_length,\n    temperature=0.7,\n    top_p=0.9,\n    top_k=50\n):\n    \"\"\"Generate text using the model.\"\"\"\n    \n    model.eval()\n    \n    # Tokenize input\n    inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n    \n    with torch.no_grad():\n        # Generate\n        outputs = model.generate(\n            inputs,\n            max_length=max_length,\n            temperature=temperature,\n            top_p=top_p,\n            top_k=top_k,\n            do_sample=True,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n            repetition_penalty=1.1\n        )\n    \n    # Decode generated text\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:31.728675Z","iopub.execute_input":"2025-06-21T05:40:31.729288Z","iopub.status.idle":"2025-06-21T05:40:31.735219Z","shell.execute_reply.started":"2025-06-21T05:40:31.729268Z","shell.execute_reply":"2025-06-21T05:40:31.734543Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"## Custom dataset","metadata":{}},{"cell_type":"code","source":"class WikiViDataset(Dataset):\n    def __init__(self, dataset, tokenizer, max_length):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        # Get data\n        item = self.dataset[idx]\n        combined_text = f\"Tiêu đề: {item['title']}\\n\\nNội dung: {item['text']}\"\n\n        # Tokenize data\n        tokenized_text = self.tokenizer(\n            combined_text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n\n        # # Print a tokenized sample\n        # print(tokenized_text)\n\n        # Prepare data from tokenizer output\n        input_ids = tokenized_text[\"input_ids\"].squeeze()\n        attention_mask = tokenized_text[\"attention_mask\"].squeeze()\n        labels = input_ids.clone() # In causal LM, labels is the same with input_ids\n        labels[attention_mask == 0] = -100 # Do not calculate loss on padding tokens\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:31.736006Z","iopub.execute_input":"2025-06-21T05:40:31.736236Z","iopub.status.idle":"2025-06-21T05:40:31.755901Z","shell.execute_reply.started":"2025-06-21T05:40:31.736213Z","shell.execute_reply":"2025-06-21T05:40:31.755139Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Load wikipedia_vi dataset","metadata":{}},{"cell_type":"code","source":"print(\"Loading dataset...\")\ndataset = load_dataset(config.dataset_name, split=\"train\")\nprint(f\"Dataset loaded. Total samples: {len(dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:31.756637Z","iopub.execute_input":"2025-06-21T05:40:31.756817Z","iopub.status.idle":"2025-06-21T05:40:40.390296Z","shell.execute_reply.started":"2025-06-21T05:40:31.756803Z","shell.execute_reply":"2025-06-21T05:40:40.389650Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f10cfca3fecb4c12ac354157060dc7a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00003-6218d2963e302058.parquet:   0%|          | 0.00/245M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ee6ec790a944100994cc84ba0c7f283"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00001-of-00003-12e6c4fadbec91d4.parquet:   0%|          | 0.00/55.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1a6f8d9977d4e0f96457ea2faccee50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00002-of-00003-175fcfe1c45b0b85.parquet:   0%|          | 0.00/270M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6012423aa47543fe957446838c275d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1284930 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa29f10fcd9c4085a6c0c8fd86ee8c6a"}},"metadata":{}},{"name":"stdout","text":"Dataset loaded. Total samples: 1284930\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:40.391132Z","iopub.execute_input":"2025-06-21T05:40:40.391634Z","iopub.status.idle":"2025-06-21T05:40:40.400691Z","shell.execute_reply.started":"2025-06-21T05:40:40.391607Z","shell.execute_reply":"2025-06-21T05:40:40.400110Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'id': 2,\n 'revid': '90949',\n 'url': 'https://vi.wikipedia.org/wiki?curid=2',\n 'title': 'Trang Chính',\n 'text': '&lt;templatestyles src=\"Wiki2021/styles.css\" /&gt;__NOEDITSECTION__\\n \\n \\n \\n '}"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"# keep only title and text column\ndataset = dataset.select_columns(['title', 'text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:40.401289Z","iopub.execute_input":"2025-06-21T05:40:40.401479Z","iopub.status.idle":"2025-06-21T05:40:44.337192Z","shell.execute_reply.started":"2025-06-21T05:40:40.401464Z","shell.execute_reply":"2025-06-21T05:40:44.336388Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:44.338001Z","iopub.execute_input":"2025-06-21T05:40:44.338267Z","iopub.status.idle":"2025-06-21T05:40:45.269421Z","shell.execute_reply.started":"2025-06-21T05:40:44.338245Z","shell.execute_reply":"2025-06-21T05:40:45.268626Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'title': 'Trang Chính',\n 'text': '&lt;templatestyles src=\"Wiki2021/styles.css\" /&gt;__NOEDITSECTION__\\n \\n \\n \\n '}"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def filter_function(example):\n    \"\"\"Filter out empty or very short texts\"\"\"\n    \n    return (\n        example['text'] is not None and \n        example['title'] is not None and\n        len(example['text'].strip()) > config.min_text_length\n    )\n\ndataset = dataset.filter(filter_function)\nprint(f\"After filtering: {len(dataset)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:45.270335Z","iopub.execute_input":"2025-06-21T05:40:45.270627Z","iopub.status.idle":"2025-06-21T05:40:55.444607Z","shell.execute_reply.started":"2025-06-21T05:40:45.270603Z","shell.execute_reply":"2025-06-21T05:40:55.444018Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1284930 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64bff61c693645b29c7716fe6a9b418e"}},"metadata":{}},{"name":"stdout","text":"After filtering: 1263196 samples\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Create splits","metadata":{}},{"cell_type":"code","source":"dataset = dataset.shuffle(seed=config.random_seed)\n\ntrain_split = dataset.select(range(\n    config.train_size\n))\n\nvalid_split = dataset.select(range(\n    config.train_size,\n    config.train_size + config.valid_size\n))\n\ntest_split = dataset.select(range(\n    config.train_size + config.valid_size,\n    config.train_size + config.valid_size + config.test_size\n))\n\nprint(f'train split: {len(train_split)} samples')\nprint(f'valid split: {len(valid_split)} samples')\nprint(f'test split: {len(test_split)} samples')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:55.445388Z","iopub.execute_input":"2025-06-21T05:40:55.445669Z","iopub.status.idle":"2025-06-21T05:40:55.803914Z","shell.execute_reply.started":"2025-06-21T05:40:55.445645Z","shell.execute_reply":"2025-06-21T05:40:55.803125Z"}},"outputs":[{"name":"stdout","text":"train split: 10000 samples\nvalid split: 10000 samples\ntest split: 5000 samples\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_ds = WikiViDataset(train_split, tokenizer, config.max_length)\nvalid_ds = WikiViDataset(valid_split, tokenizer, config.max_length)\ntest_ds = WikiViDataset(test_split, tokenizer, config.max_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:55.804699Z","iopub.execute_input":"2025-06-21T05:40:55.804895Z","iopub.status.idle":"2025-06-21T05:40:59.104956Z","shell.execute_reply.started":"2025-06-21T05:40:55.804879Z","shell.execute_reply":"2025-06-21T05:40:59.104339Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# # Display a sample\n# train_ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.105834Z","iopub.execute_input":"2025-06-21T05:40:59.106088Z","iopub.status.idle":"2025-06-21T05:40:59.123754Z","shell.execute_reply.started":"2025-06-21T05:40:59.106065Z","shell.execute_reply":"2025-06-21T05:40:59.123113Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Data loader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(\n    train_ds,\n    batch_size=config.per_device_train_batch_size,\n    shuffle=True,\n    num_workers=config.num_workers,\n    pin_memory=True,\n)\n\nvalid_dataloader = DataLoader(\n    valid_ds,\n    batch_size=config.per_device_valid_batch_size,\n    shuffle=True,\n    num_workers=config.num_workers,\n    pin_memory=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.124467Z","iopub.execute_input":"2025-06-21T05:40:59.124711Z","iopub.status.idle":"2025-06-21T05:40:59.143825Z","shell.execute_reply.started":"2025-06-21T05:40:59.124696Z","shell.execute_reply":"2025-06-21T05:40:59.143265Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(f\"Train batches: {len(train_dataloader)}\")\nprint(f\"Valid batches: {len(valid_dataloader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.144567Z","iopub.execute_input":"2025-06-21T05:40:59.144845Z","iopub.status.idle":"2025-06-21T05:40:59.165897Z","shell.execute_reply.started":"2025-06-21T05:40:59.144819Z","shell.execute_reply":"2025-06-21T05:40:59.165194Z"}},"outputs":[{"name":"stdout","text":"Train batches: 5000\nValid batches: 5000\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Optimizer & scheduler","metadata":{}},{"cell_type":"code","source":"total_steps = len(train_dataloader) * config.num_train_epochs // config.gradient_accumulation_steps\nwarmup_steps = int(total_steps * config.warmup_ratio)\n\nprint(f\"Total training steps: {total_steps}\")\nprint(f\"Warmup steps: {warmup_steps}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.166810Z","iopub.execute_input":"2025-06-21T05:40:59.167045Z","iopub.status.idle":"2025-06-21T05:40:59.184412Z","shell.execute_reply.started":"2025-06-21T05:40:59.167030Z","shell.execute_reply":"2025-06-21T05:40:59.183854Z"}},"outputs":[{"name":"stdout","text":"Total training steps: 1875\nWarmup steps: 187\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Setup optimizer\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=config.learning_rate,\n    weight_decay=config.weight_decay,\n    eps=config.adam_epsilon\n)\n\n# Setup learning rate scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)\n\n# Setup gradient scaler for mixed precision training\nscaler = torch.amp.GradScaler(device) if config.fp16 else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.185024Z","iopub.execute_input":"2025-06-21T05:40:59.185203Z","iopub.status.idle":"2025-06-21T05:40:59.203885Z","shell.execute_reply.started":"2025-06-21T05:40:59.185189Z","shell.execute_reply":"2025-06-21T05:40:59.203128Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# Training function","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, scheduler, scaler, epoch):\n    \"\"\"Train for one epoch.\"\"\"\n    \n    model.train()\n    total_loss = 0\n    optimizer.zero_grad()\n    \n    progress_bar = tqdm(dataloader, desc=f\"Training Epoch {epoch + 1}\")\n    \n    for step, batch in enumerate(progress_bar):\n        # Move batch to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        # Forward pass with mixed precision\n        if config.fp16:\n            # For mixed precision\n            with torch.autocast(device_type=device.type):\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels\n                )\n                # Chia loss cho gradient_accumulation_steps\n                # Nếu không nhận được loss sẽ gấp <gradient_accumulation_steps> lần loss thực sự\n                loss = outputs.loss / config.gradient_accumulation_steps\n        else:\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            loss = outputs.loss / config.gradient_accumulation_steps\n        \n        # Backward pass\n        if config.fp16:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        \n        total_loss += loss.item()\n        \n        # Update weights every gradient_accumulation_steps\n        if (step + 1) % config.gradient_accumulation_steps == 0:\n            if config.fp16:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n                optimizer.step()\n            \n            scheduler.step()\n            optimizer.zero_grad()\n        \n        # Update progress bar\n        progress_bar.set_postfix({\n            'loss': f\"{loss.item() * config.gradient_accumulation_steps:.4f}\",\n            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n        })\n        \n        # Logging\n        if (step + 1) % config.logging_steps == 0:\n            \n            avg_loss = total_loss / (step + 1) * config.gradient_accumulation_steps\n            print(f\"Step {step + 1}/{len(dataloader)}, Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.2e}\")\n\n            if config.use_wandb:\n                wandb.log({\n                    \"train_loss\": avg_loss,\n                    \"learning_rate\": scheduler.get_last_lr()[0],\n                    \"train_step\": epoch * len(dataloader) + step + 1\n                })\n    \n    return total_loss / len(dataloader) * config.gradient_accumulation_steps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.204653Z","iopub.execute_input":"2025-06-21T05:40:59.204815Z","iopub.status.idle":"2025-06-21T05:40:59.225413Z","shell.execute_reply.started":"2025-06-21T05:40:59.204802Z","shell.execute_reply":"2025-06-21T05:40:59.224750Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Validation function","metadata":{}},{"cell_type":"code","source":"def validate(model, dataloader):\n    \"\"\"Validate the model.\"\"\"\n    \n    model.eval()\n    total_loss = 0\n    total_steps = 0\n    \n    with torch.no_grad():\n        progress_bar = tqdm(dataloader, desc=\"Validating\")\n        \n        for batch in progress_bar:\n            # Move batch to device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            # Forward pass\n            if config.fp16:\n                with torch.autocast(device_type=device.type):\n                    outputs = model(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        labels=labels\n                    )\n            else:\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels\n                )\n            \n            loss = outputs.loss\n            total_loss += loss.item()\n            total_steps += 1\n            \n            progress_bar.set_postfix({'valid_loss': f\"{loss.item():.4f}\"})\n    \n    avg_loss = total_loss / total_steps\n    perplexity = math.exp(avg_loss)\n    \n    return avg_loss, perplexity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.226200Z","iopub.execute_input":"2025-06-21T05:40:59.226383Z","iopub.status.idle":"2025-06-21T05:40:59.254057Z","shell.execute_reply.started":"2025-06-21T05:40:59.226369Z","shell.execute_reply":"2025-06-21T05:40:59.253235Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"markdown","source":"## Test before training","metadata":{}},{"cell_type":"code","source":"test_prompts = [\n    \"Việt Nam là một quốc gia\",\n    \"Tiêu đề: Hà Nội\\n\\nNội dung:\",\n    \"Lịch sử Việt Nam bắt đầu từ\",\n    \"Văn hóa truyền thống của người Việt\",\n    \"Tiêu đề: Phở\\n\\nNội dung: Phở là\"\n]\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"TESTING THE ORIGINAL MODEL\")\nprint(\"=\" * 50)\n\nfor i, prompt in enumerate(test_prompts, 1):\n    print(f\"\\n--- Test {i} ---\")\n    print(f\"Prompt: {prompt}\")\n    print(\"-\" * 40)\n    \n    generated = generate_text(prompt, max_length=150, temperature=0.7)\n    print(f\"Generated: {generated}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:40:59.254992Z","iopub.execute_input":"2025-06-21T05:40:59.255297Z","iopub.status.idle":"2025-06-21T05:41:38.147234Z","shell.execute_reply.started":"2025-06-21T05:40:59.255274Z","shell.execute_reply":"2025-06-21T05:41:38.146555Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nTESTING THE ORIGINAL MODEL\n==================================================\n\n--- Test 1 ---\nPrompt: Việt Nam là một quốc gia\n----------------------------------------\nGenerated: Việt Nam là một quốc gia toàn diện và có nhiều hoạt động ngoại giao. Hãy cho biết các chương trình chính trị, văn hóa, giáo dục, công tác dân số, và công tác nhân dân trong khu vực 1930-2040?\n\nVui lòng giúp tôi chọn tên đúng tiếng Việt\n\nCâu hỏi: Hãy chọn tên đúng tiếng Việt cho \"chương trình chính trị\" trong chương trình chính trị.\n\nA) Vĩ thạch anh\nB) Mục tiêu\nC) Tham vọng\nD) Chiến lược\n\nKhi người Việt Nam yêu thích những vấn đề như thế, hãy nêu một ví dụ về việc thực hiện các cơ sở hạ tầng công cộng của Chính\n\n--- Test 2 ---\nPrompt: Tiêu đề: Hà Nội\n\nNội dung:\n----------------------------------------\nGenerated: Tiêu đề: Hà Nội\n\nNội dung: Một số từ trong tiếng Anh có thể được viết bằng tiếng Việt như sau: \"Vắng\" (vị trí) – \"Có\" (phân tích) – \"Từ\" (thuật) – \"Đến\" (đoàn). \n\nHãy lập một bài báo ngắn gọn về một thành phố nào, gồm các phần: tiêu đề, mở đầu, nội dung và kết thúc.\n\nBài báo cần phải nói đến 3 thành phần cơ bản của một thành phố: nhà ở, trường học, và văn hóa.\n\n**Gửi lại dưới đây**\n\n---\n\n**Một bài báo ngắn gọn**\n\n---\n\n**Tiêu đề:**\n\n--- Test 3 ---\nPrompt: Lịch sử Việt Nam bắt đầu từ\n----------------------------------------\nGenerated: Lịch sử Việt Nam bắt đầu từ những năm 1940s, nhưng trong thời gian này, lịch sử của người dân trong các thành phố lớn được bao nhiêu?\nA. 38%\nB. 26%\nC. 75%\nD. 12%\nĐáp án đúng là B. 26% - vì lý do gì? Vì sao tôi nên chọn câu trả lời đúng?\n\nTại sao người ta chọn A. 38%? \n\nCâu hỏi: \"Lịch sử Việt Nam bắt đầu từ những năm 1940s\" có thể cho thấy rằng:\n\nA. Người Việt Nam là một dân tộc phân chia\nB. Người\n\n--- Test 4 ---\nPrompt: Văn hóa truyền thống của người Việt\n----------------------------------------\nGenerated: Văn hóa truyền thống của người Việt là gì?\nA. Văn hóa truyền thống là một hình thức thể hiện nghệ thuật\nB. Văn hóa truyền thống là một hình thức thể hiện nghệ thuật kỹ lưỡng\nC. Văn hóa truyền thống là một hình thức thể hiện nghệ thuật tổng thể\nD. Không phải là câu trả lời đúng\nAnswer:\nA\n\nB\n\nC\n\nD\n\nKết luận, câu trả lời đúng là C.\nAnswer:\n\n**C**\n\nVăn hóa truyền thống là một hình thức thể hiện nghệ thuật tổng thể.\n\nGiải thích: Các lựa chọn khác không đúng với nội dung bài kiểm tra. Văn hóa truyền thống là một hình thức thể hiện nghệ thuật tổng thể (theo C). Bạn\n\n--- Test 5 ---\nPrompt: Tiêu đề: Phở\n\nNội dung: Phở là\n----------------------------------------\nGenerated: Tiêu đề: Phở\n\nNội dung: Phở là một loại thức ăn trong nhà, được làm từ các món ăn khác. Những người đi bộ có nhiều cơ hội để đi qua những nơi với bạn bè và kết nối với nhau.\n\nMột số tiêu đề mô phỏng:\n\n1. Phở\n2. Phở Trưa\n3. Phở Giao Động\n4. Phở Lối Mạng\n5. Phở Khu\n6. Phở Trung\n7. Phở Cao\n\n8. Phở Hồi\n9. Phở Món\n10. Phở Chơi\n\nBài viết ngắn về phở sẽ có tiêu đề giống như sau:\n\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Main loop","metadata":{}},{"cell_type":"code","source":"print(\"Starting training...\")\n\n# Create output directory\nos.makedirs(config.output_dir, exist_ok=True)\n\n# Training history\ntraining_history = {\n    'train_losses': [],\n    'train_times': [],\n    'valid_losses': [],\n    'valid_perplexities': [],\n    'valid_times': [],\n    'learning_rates': []\n}\n\nbest_valid_loss = float('inf')\nstep_count = 0\n\nfor epoch in range(config.num_train_epochs):\n    print(f\"\\n{'=' * 50}\")\n    print(f\"Epoch {epoch + 1}/{config.num_train_epochs}\")\n    print(f\"{'=' * 50}\")\n    \n    # Training\n    start_time = time.time()\n    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, scaler, epoch)\n    end_time = time.time()\n    \n    elapsed_time = end_time - start_time\n    train_mins, train_secs = divmod(elapsed_time, 60)\n    training_history['train_times'].append(train_mins)\n    print(f\"Training Time: {int(train_mins)} mins {int(train_secs)} seconds\")\n    \n    training_history['train_losses'].append(train_loss)\n    print(f\"Training Loss: {train_loss:.4f}\")\n    \n    # Validation\n    start_time = time.time()\n    valid_loss, perplexity = validate(model, valid_dataloader)\n    end_time = time.time()\n    \n    elapsed_time = end_time - start_time\n    valid_mins, valid_secs = divmod(elapsed_time, 60)\n    training_history['valid_times'].append(valid_mins)\n    print(f\"Training Time: {int(valid_mins)} mins {int(valid_secs)} seconds\")\n    \n    training_history['valid_losses'].append(valid_loss)\n    training_history['valid_perplexities'].append(perplexity)\n    print(f\"Validation Loss: {valid_loss:.4f}\")\n    print(f\"Perplexity: {perplexity:.2f}\")\n    \n    # Log to wandb\n    if config.use_wandb:\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_time (m)\": train_mins,\n            \"valid_time (m)\": valid_mins,\n            \"valid_loss\": valid_loss,\n            \"perplexity\": perplexity,\n        })\n    \n    # Save best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        \n        model.save_pretrained(config.output_dir)\n        tokenizer.save_pretrained(config.output_dir)\n        print(f\"New best model! Saved to {config.output_dir}\")\n        \n        if config.use_hf:\n            model.push_to_hub(config.hf_repo)\n            tokenizer.push_to_hub(config.hf_repo)\n            print(f\"Also saved to repo {config.hf_repo}\")\n        \n    # Save training state\n    torch.save({\n        'epoch': epoch + 1,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'best_valid_loss': best_valid_loss,\n        'training_history': training_history\n    }, os.path.join(config.output_dir, 'training_state.pt'))\n    print(f\"Training state saved to {config.output_dir}!\")\n\n    if config.use_hf:\n        hf_api.upload_file(\n            path_or_fileobj=os.path.join(config.output_dir, 'training_state.pt'),\n            path_in_repo=\"training_state.pt\",\n            repo_id=config.hf_repo,\n            repo_type=\"model\",\n        )\n    print(f\"Training state pushed to repo {config.hf_repo}!\")\n    \n    # Clean up GPU memory\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T05:41:38.150399Z","iopub.execute_input":"2025-06-21T05:41:38.150695Z","iopub.status.idle":"2025-06-21T07:34:19.925472Z","shell.execute_reply.started":"2025-06-21T05:41:38.150676Z","shell.execute_reply":"2025-06-21T07:34:19.924540Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n\n==================================================\nEpoch 1/3\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 1:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93e25945b044713a31d5f6a91143d05"}},"metadata":{}},{"name":"stdout","text":"Step 40/5000, Loss: 3.2866, LR: 1.34e-06\nStep 80/5000, Loss: 3.2858, LR: 2.67e-06\nStep 120/5000, Loss: 3.2644, LR: 4.01e-06\nStep 160/5000, Loss: 3.2250, LR: 5.35e-06\nStep 200/5000, Loss: 3.2332, LR: 6.68e-06\nStep 240/5000, Loss: 3.2153, LR: 8.02e-06\nStep 280/5000, Loss: 3.2169, LR: 9.36e-06\nStep 320/5000, Loss: 3.1953, LR: 1.07e-05\nStep 360/5000, Loss: 3.1768, LR: 1.20e-05\nStep 400/5000, Loss: 3.1459, LR: 1.34e-05\nStep 440/5000, Loss: 3.1265, LR: 1.47e-05\nStep 480/5000, Loss: 3.0896, LR: 1.60e-05\nStep 520/5000, Loss: 3.0649, LR: 1.74e-05\nStep 560/5000, Loss: 3.0419, LR: 1.87e-05\nStep 600/5000, Loss: 3.0180, LR: 2.01e-05\nStep 640/5000, Loss: 2.9964, LR: 2.14e-05\nStep 680/5000, Loss: 2.9701, LR: 2.27e-05\nStep 720/5000, Loss: 2.9492, LR: 2.41e-05\nStep 760/5000, Loss: 2.9282, LR: 2.54e-05\nStep 800/5000, Loss: 2.9063, LR: 2.67e-05\nStep 840/5000, Loss: 2.8876, LR: 2.81e-05\nStep 880/5000, Loss: 2.8638, LR: 2.94e-05\nStep 920/5000, Loss: 2.8429, LR: 3.07e-05\nStep 960/5000, Loss: 2.8225, LR: 3.21e-05\nStep 1000/5000, Loss: 2.8041, LR: 3.34e-05\nStep 1040/5000, Loss: 2.7844, LR: 3.48e-05\nStep 1080/5000, Loss: 2.7649, LR: 3.61e-05\nStep 1120/5000, Loss: 2.7515, LR: 3.74e-05\nStep 1160/5000, Loss: 2.7346, LR: 3.88e-05\nStep 1200/5000, Loss: 2.7173, LR: 4.01e-05\nStep 1240/5000, Loss: 2.7007, LR: 4.14e-05\nStep 1280/5000, Loss: 2.6867, LR: 4.28e-05\nStep 1320/5000, Loss: 2.6698, LR: 4.41e-05\nStep 1360/5000, Loss: 2.6563, LR: 4.55e-05\nStep 1400/5000, Loss: 2.6445, LR: 4.68e-05\nStep 1440/5000, Loss: 2.6332, LR: 4.81e-05\nStep 1480/5000, Loss: 2.6215, LR: 4.95e-05\nStep 1520/5000, Loss: 2.6094, LR: 4.99e-05\nStep 1560/5000, Loss: 2.5998, LR: 4.98e-05\nStep 1600/5000, Loss: 2.5880, LR: 4.96e-05\nStep 1640/5000, Loss: 2.5782, LR: 4.95e-05\nStep 1680/5000, Loss: 2.5662, LR: 4.93e-05\nStep 1720/5000, Loss: 2.5562, LR: 4.92e-05\nStep 1760/5000, Loss: 2.5452, LR: 4.90e-05\nStep 1800/5000, Loss: 2.5387, LR: 4.89e-05\nStep 1840/5000, Loss: 2.5310, LR: 4.87e-05\nStep 1880/5000, Loss: 2.5218, LR: 4.86e-05\nStep 1920/5000, Loss: 2.5068, LR: 4.84e-05\nStep 1960/5000, Loss: 2.5010, LR: 4.83e-05\nStep 2000/5000, Loss: 2.4863, LR: 4.81e-05\nStep 2040/5000, Loss: 2.4759, LR: 4.80e-05\nStep 2080/5000, Loss: 2.4679, LR: 4.78e-05\nStep 2120/5000, Loss: 2.4628, LR: 4.77e-05\nStep 2160/5000, Loss: 2.4544, LR: 4.75e-05\nStep 2200/5000, Loss: 2.4474, LR: 4.74e-05\nStep 2240/5000, Loss: 2.4408, LR: 4.72e-05\nStep 2280/5000, Loss: 2.4327, LR: 4.71e-05\nStep 2320/5000, Loss: 2.4255, LR: 4.69e-05\nStep 2360/5000, Loss: 2.4196, LR: 4.68e-05\nStep 2400/5000, Loss: 2.4118, LR: 4.67e-05\nStep 2440/5000, Loss: 2.4043, LR: 4.65e-05\nStep 2480/5000, Loss: 2.3976, LR: 4.64e-05\nStep 2520/5000, Loss: 2.3903, LR: 4.62e-05\nStep 2560/5000, Loss: 2.3835, LR: 4.61e-05\nStep 2600/5000, Loss: 2.3765, LR: 4.59e-05\nStep 2640/5000, Loss: 2.3708, LR: 4.58e-05\nStep 2680/5000, Loss: 2.3624, LR: 4.56e-05\nStep 2720/5000, Loss: 2.3540, LR: 4.55e-05\nStep 2760/5000, Loss: 2.3464, LR: 4.53e-05\nStep 2800/5000, Loss: 2.3411, LR: 4.52e-05\nStep 2840/5000, Loss: 2.3371, LR: 4.50e-05\nStep 2880/5000, Loss: 2.3312, LR: 4.49e-05\nStep 2920/5000, Loss: 2.3239, LR: 4.47e-05\nStep 2960/5000, Loss: 2.3191, LR: 4.46e-05\nStep 3000/5000, Loss: 2.3136, LR: 4.44e-05\nStep 3040/5000, Loss: 2.3067, LR: 4.43e-05\nStep 3080/5000, Loss: 2.2997, LR: 4.41e-05\nStep 3120/5000, Loss: 2.2967, LR: 4.40e-05\nStep 3160/5000, Loss: 2.2916, LR: 4.38e-05\nStep 3200/5000, Loss: 2.2868, LR: 4.37e-05\nStep 3240/5000, Loss: 2.2830, LR: 4.35e-05\nStep 3280/5000, Loss: 2.2771, LR: 4.34e-05\nStep 3320/5000, Loss: 2.2715, LR: 4.32e-05\nStep 3360/5000, Loss: 2.2675, LR: 4.31e-05\nStep 3400/5000, Loss: 2.2636, LR: 4.30e-05\nStep 3440/5000, Loss: 2.2584, LR: 4.28e-05\nStep 3480/5000, Loss: 2.2551, LR: 4.27e-05\nStep 3520/5000, Loss: 2.2513, LR: 4.25e-05\nStep 3560/5000, Loss: 2.2451, LR: 4.24e-05\nStep 3600/5000, Loss: 2.2405, LR: 4.22e-05\nStep 3640/5000, Loss: 2.2356, LR: 4.21e-05\nStep 3680/5000, Loss: 2.2317, LR: 4.19e-05\nStep 3720/5000, Loss: 2.2274, LR: 4.18e-05\nStep 3760/5000, Loss: 2.2222, LR: 4.16e-05\nStep 3800/5000, Loss: 2.2183, LR: 4.15e-05\nStep 3840/5000, Loss: 2.2131, LR: 4.13e-05\nStep 3880/5000, Loss: 2.2077, LR: 4.12e-05\nStep 3920/5000, Loss: 2.2048, LR: 4.10e-05\nStep 3960/5000, Loss: 2.2013, LR: 4.09e-05\nStep 4000/5000, Loss: 2.1956, LR: 4.07e-05\nStep 4040/5000, Loss: 2.1900, LR: 4.06e-05\nStep 4080/5000, Loss: 2.1851, LR: 4.04e-05\nStep 4120/5000, Loss: 2.1797, LR: 4.03e-05\nStep 4160/5000, Loss: 2.1767, LR: 4.01e-05\nStep 4200/5000, Loss: 2.1727, LR: 4.00e-05\nStep 4240/5000, Loss: 2.1701, LR: 3.98e-05\nStep 4280/5000, Loss: 2.1670, LR: 3.97e-05\nStep 4320/5000, Loss: 2.1639, LR: 3.95e-05\nStep 4360/5000, Loss: 2.1611, LR: 3.94e-05\nStep 4400/5000, Loss: 2.1577, LR: 3.92e-05\nStep 4440/5000, Loss: 2.1538, LR: 3.91e-05\nStep 4480/5000, Loss: 2.1503, LR: 3.90e-05\nStep 4520/5000, Loss: 2.1466, LR: 3.88e-05\nStep 4560/5000, Loss: 2.1421, LR: 3.87e-05\nStep 4600/5000, Loss: 2.1387, LR: 3.85e-05\nStep 4640/5000, Loss: 2.1351, LR: 3.84e-05\nStep 4680/5000, Loss: 2.1321, LR: 3.82e-05\nStep 4720/5000, Loss: 2.1283, LR: 3.81e-05\nStep 4760/5000, Loss: 2.1249, LR: 3.79e-05\nStep 4800/5000, Loss: 2.1210, LR: 3.78e-05\nStep 4840/5000, Loss: 2.1186, LR: 3.76e-05\nStep 4880/5000, Loss: 2.1151, LR: 3.75e-05\nStep 4920/5000, Loss: 2.1113, LR: 3.73e-05\nStep 4960/5000, Loss: 2.1074, LR: 3.72e-05\nStep 5000/5000, Loss: 2.1034, LR: 3.70e-05\nTraining Time: 27 mins 7 seconds\nTraining Loss: 2.1034\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e82aea1b564de2bd8f74ff40075cfd"}},"metadata":{}},{"name":"stdout","text":"Training Time: 8 mins 18 seconds\nValidation Loss: 1.7042\nPerplexity: 5.50\nNew best model! Saved to ./qwen-vietnamese-wiki-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/870M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21ed94401284a7a96d36af0b095a032"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5956ba89d03c45dab10bf360ade59cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788f2a872ada44f1902bf685e14290c4"}},"metadata":{}},{"name":"stdout","text":"Also saved to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU\nTraining state saved to ./qwen-vietnamese-wiki-finetuned!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"training_state.pt:   0%|          | 0.00/2.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"927583a6c2b74f9a9e244ab797d3010e"}},"metadata":{}},{"name":"stdout","text":"Training state pushed to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU!\n\n==================================================\nEpoch 2/3\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 2:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c3701523a84d2797f8379f010d6d2e"}},"metadata":{}},{"name":"stdout","text":"Step 40/5000, Loss: 1.6574, LR: 3.69e-05\nStep 80/5000, Loss: 1.6156, LR: 3.67e-05\nStep 120/5000, Loss: 1.6194, LR: 3.66e-05\nStep 160/5000, Loss: 1.5958, LR: 3.64e-05\nStep 200/5000, Loss: 1.5789, LR: 3.63e-05\nStep 240/5000, Loss: 1.5747, LR: 3.61e-05\nStep 280/5000, Loss: 1.5720, LR: 3.60e-05\nStep 320/5000, Loss: 1.5618, LR: 3.58e-05\nStep 360/5000, Loss: 1.5669, LR: 3.57e-05\nStep 400/5000, Loss: 1.5713, LR: 3.55e-05\nStep 440/5000, Loss: 1.5781, LR: 3.54e-05\nStep 480/5000, Loss: 1.5829, LR: 3.52e-05\nStep 520/5000, Loss: 1.5760, LR: 3.51e-05\nStep 560/5000, Loss: 1.5678, LR: 3.50e-05\nStep 600/5000, Loss: 1.5546, LR: 3.48e-05\nStep 640/5000, Loss: 1.5411, LR: 3.47e-05\nStep 680/5000, Loss: 1.5301, LR: 3.45e-05\nStep 720/5000, Loss: 1.5409, LR: 3.44e-05\nStep 760/5000, Loss: 1.5425, LR: 3.42e-05\nStep 800/5000, Loss: 1.5402, LR: 3.41e-05\nStep 840/5000, Loss: 1.5372, LR: 3.39e-05\nStep 880/5000, Loss: 1.5375, LR: 3.38e-05\nStep 920/5000, Loss: 1.5305, LR: 3.36e-05\nStep 960/5000, Loss: 1.5363, LR: 3.35e-05\nStep 1000/5000, Loss: 1.5409, LR: 3.33e-05\nStep 1040/5000, Loss: 1.5429, LR: 3.32e-05\nStep 1080/5000, Loss: 1.5441, LR: 3.30e-05\nStep 1120/5000, Loss: 1.5436, LR: 3.29e-05\nStep 1160/5000, Loss: 1.5406, LR: 3.27e-05\nStep 1200/5000, Loss: 1.5410, LR: 3.26e-05\nStep 1240/5000, Loss: 1.5396, LR: 3.24e-05\nStep 1280/5000, Loss: 1.5378, LR: 3.23e-05\nStep 1320/5000, Loss: 1.5379, LR: 3.21e-05\nStep 1360/5000, Loss: 1.5420, LR: 3.20e-05\nStep 1400/5000, Loss: 1.5433, LR: 3.18e-05\nStep 1440/5000, Loss: 1.5438, LR: 3.17e-05\nStep 1480/5000, Loss: 1.5409, LR: 3.15e-05\nStep 1520/5000, Loss: 1.5374, LR: 3.14e-05\nStep 1560/5000, Loss: 1.5419, LR: 3.13e-05\nStep 1600/5000, Loss: 1.5416, LR: 3.11e-05\nStep 1640/5000, Loss: 1.5386, LR: 3.10e-05\nStep 1680/5000, Loss: 1.5366, LR: 3.08e-05\nStep 1720/5000, Loss: 1.5369, LR: 3.07e-05\nStep 1760/5000, Loss: 1.5375, LR: 3.05e-05\nStep 1800/5000, Loss: 1.5386, LR: 3.04e-05\nStep 1840/5000, Loss: 1.5390, LR: 3.02e-05\nStep 1880/5000, Loss: 1.5380, LR: 3.01e-05\nStep 1920/5000, Loss: 1.5400, LR: 2.99e-05\nStep 1960/5000, Loss: 1.5431, LR: 2.98e-05\nStep 2000/5000, Loss: 1.5438, LR: 2.96e-05\nStep 2040/5000, Loss: 1.5436, LR: 2.95e-05\nStep 2080/5000, Loss: 1.5472, LR: 2.93e-05\nStep 2120/5000, Loss: 1.5444, LR: 2.92e-05\nStep 2160/5000, Loss: 1.5429, LR: 2.90e-05\nStep 2200/5000, Loss: 1.5445, LR: 2.89e-05\nStep 2240/5000, Loss: 1.5435, LR: 2.87e-05\nStep 2280/5000, Loss: 1.5452, LR: 2.86e-05\nStep 2320/5000, Loss: 1.5432, LR: 2.84e-05\nStep 2360/5000, Loss: 1.5430, LR: 2.83e-05\nStep 2400/5000, Loss: 1.5439, LR: 2.81e-05\nStep 2440/5000, Loss: 1.5425, LR: 2.80e-05\nStep 2480/5000, Loss: 1.5416, LR: 2.78e-05\nStep 2520/5000, Loss: 1.5425, LR: 2.77e-05\nStep 2560/5000, Loss: 1.5430, LR: 2.75e-05\nStep 2600/5000, Loss: 1.5447, LR: 2.74e-05\nStep 2640/5000, Loss: 1.5473, LR: 2.73e-05\nStep 2680/5000, Loss: 1.5486, LR: 2.71e-05\nStep 2720/5000, Loss: 1.5493, LR: 2.70e-05\nStep 2760/5000, Loss: 1.5471, LR: 2.68e-05\nStep 2800/5000, Loss: 1.5467, LR: 2.67e-05\nStep 2840/5000, Loss: 1.5480, LR: 2.65e-05\nStep 2880/5000, Loss: 1.5470, LR: 2.64e-05\nStep 2920/5000, Loss: 1.5467, LR: 2.62e-05\nStep 2960/5000, Loss: 1.5459, LR: 2.61e-05\nStep 3000/5000, Loss: 1.5450, LR: 2.59e-05\nStep 3040/5000, Loss: 1.5435, LR: 2.58e-05\nStep 3080/5000, Loss: 1.5438, LR: 2.56e-05\nStep 3120/5000, Loss: 1.5423, LR: 2.55e-05\nStep 3160/5000, Loss: 1.5445, LR: 2.53e-05\nStep 3200/5000, Loss: 1.5423, LR: 2.52e-05\nStep 3240/5000, Loss: 1.5428, LR: 2.50e-05\nStep 3280/5000, Loss: 1.5406, LR: 2.49e-05\nStep 3320/5000, Loss: 1.5409, LR: 2.47e-05\nStep 3360/5000, Loss: 1.5405, LR: 2.46e-05\nStep 3400/5000, Loss: 1.5407, LR: 2.44e-05\nStep 3440/5000, Loss: 1.5393, LR: 2.43e-05\nStep 3480/5000, Loss: 1.5387, LR: 2.41e-05\nStep 3520/5000, Loss: 1.5384, LR: 2.40e-05\nStep 3560/5000, Loss: 1.5372, LR: 2.38e-05\nStep 3600/5000, Loss: 1.5387, LR: 2.37e-05\nStep 3640/5000, Loss: 1.5390, LR: 2.35e-05\nStep 3680/5000, Loss: 1.5391, LR: 2.34e-05\nStep 3720/5000, Loss: 1.5391, LR: 2.33e-05\nStep 3760/5000, Loss: 1.5378, LR: 2.31e-05\nStep 3800/5000, Loss: 1.5369, LR: 2.30e-05\nStep 3840/5000, Loss: 1.5352, LR: 2.28e-05\nStep 3880/5000, Loss: 1.5348, LR: 2.27e-05\nStep 3920/5000, Loss: 1.5357, LR: 2.25e-05\nStep 3960/5000, Loss: 1.5349, LR: 2.24e-05\nStep 4000/5000, Loss: 1.5365, LR: 2.22e-05\nStep 4040/5000, Loss: 1.5359, LR: 2.21e-05\nStep 4080/5000, Loss: 1.5374, LR: 2.19e-05\nStep 4120/5000, Loss: 1.5359, LR: 2.18e-05\nStep 4160/5000, Loss: 1.5354, LR: 2.16e-05\nStep 4200/5000, Loss: 1.5354, LR: 2.15e-05\nStep 4240/5000, Loss: 1.5353, LR: 2.13e-05\nStep 4280/5000, Loss: 1.5344, LR: 2.12e-05\nStep 4320/5000, Loss: 1.5330, LR: 2.10e-05\nStep 4360/5000, Loss: 1.5324, LR: 2.09e-05\nStep 4400/5000, Loss: 1.5315, LR: 2.07e-05\nStep 4440/5000, Loss: 1.5322, LR: 2.06e-05\nStep 4480/5000, Loss: 1.5330, LR: 2.04e-05\nStep 4520/5000, Loss: 1.5331, LR: 2.03e-05\nStep 4560/5000, Loss: 1.5325, LR: 2.01e-05\nStep 4600/5000, Loss: 1.5306, LR: 2.00e-05\nStep 4640/5000, Loss: 1.5314, LR: 1.98e-05\nStep 4680/5000, Loss: 1.5311, LR: 1.97e-05\nStep 4720/5000, Loss: 1.5308, LR: 1.95e-05\nStep 4760/5000, Loss: 1.5301, LR: 1.94e-05\nStep 4800/5000, Loss: 1.5299, LR: 1.93e-05\nStep 4840/5000, Loss: 1.5291, LR: 1.91e-05\nStep 4880/5000, Loss: 1.5291, LR: 1.90e-05\nStep 4920/5000, Loss: 1.5287, LR: 1.88e-05\nStep 4960/5000, Loss: 1.5274, LR: 1.87e-05\nStep 5000/5000, Loss: 1.5262, LR: 1.85e-05\nTraining Time: 27 mins 31 seconds\nTraining Loss: 1.5262\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93df7cdba5f4a19b7ca98dd110b6a21"}},"metadata":{}},{"name":"stdout","text":"Training Time: 8 mins 21 seconds\nValidation Loss: 1.6226\nPerplexity: 5.07\nNew best model! Saved to ./qwen-vietnamese-wiki-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/870M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b54267df164715b3d65f7bd8b4fe58"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Also saved to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU\nTraining state saved to ./qwen-vietnamese-wiki-finetuned!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"training_state.pt:   0%|          | 0.00/2.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e0dfeb54bb40bcb07a3f291704a454"}},"metadata":{}},{"name":"stdout","text":"Training state pushed to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU!\n\n==================================================\nEpoch 3/3\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 3:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3850e17a12a846c898b7ff02896c4afa"}},"metadata":{}},{"name":"stdout","text":"Step 40/5000, Loss: 1.3651, LR: 1.84e-05\nStep 80/5000, Loss: 1.3475, LR: 1.82e-05\nStep 120/5000, Loss: 1.3787, LR: 1.81e-05\nStep 160/5000, Loss: 1.3780, LR: 1.79e-05\nStep 200/5000, Loss: 1.4234, LR: 1.78e-05\nStep 240/5000, Loss: 1.4131, LR: 1.76e-05\nStep 280/5000, Loss: 1.4153, LR: 1.75e-05\nStep 320/5000, Loss: 1.4156, LR: 1.73e-05\nStep 360/5000, Loss: 1.4149, LR: 1.72e-05\nStep 400/5000, Loss: 1.4033, LR: 1.70e-05\nStep 440/5000, Loss: 1.4046, LR: 1.69e-05\nStep 480/5000, Loss: 1.4079, LR: 1.67e-05\nStep 520/5000, Loss: 1.4099, LR: 1.66e-05\nStep 560/5000, Loss: 1.4181, LR: 1.64e-05\nStep 600/5000, Loss: 1.4137, LR: 1.63e-05\nStep 640/5000, Loss: 1.4132, LR: 1.61e-05\nStep 680/5000, Loss: 1.4131, LR: 1.60e-05\nStep 720/5000, Loss: 1.4124, LR: 1.58e-05\nStep 760/5000, Loss: 1.4147, LR: 1.57e-05\nStep 800/5000, Loss: 1.4147, LR: 1.56e-05\nStep 840/5000, Loss: 1.4112, LR: 1.54e-05\nStep 880/5000, Loss: 1.4094, LR: 1.53e-05\nStep 920/5000, Loss: 1.4107, LR: 1.51e-05\nStep 960/5000, Loss: 1.4164, LR: 1.50e-05\nStep 1000/5000, Loss: 1.4162, LR: 1.48e-05\nStep 1040/5000, Loss: 1.4135, LR: 1.47e-05\nStep 1080/5000, Loss: 1.4144, LR: 1.45e-05\nStep 1120/5000, Loss: 1.4136, LR: 1.44e-05\nStep 1160/5000, Loss: 1.4132, LR: 1.42e-05\nStep 1200/5000, Loss: 1.4122, LR: 1.41e-05\nStep 1240/5000, Loss: 1.4127, LR: 1.39e-05\nStep 1280/5000, Loss: 1.4113, LR: 1.38e-05\nStep 1320/5000, Loss: 1.4144, LR: 1.36e-05\nStep 1360/5000, Loss: 1.4190, LR: 1.35e-05\nStep 1400/5000, Loss: 1.4139, LR: 1.33e-05\nStep 1440/5000, Loss: 1.4122, LR: 1.32e-05\nStep 1480/5000, Loss: 1.4138, LR: 1.30e-05\nStep 1520/5000, Loss: 1.4140, LR: 1.29e-05\nStep 1560/5000, Loss: 1.4120, LR: 1.27e-05\nStep 1600/5000, Loss: 1.4136, LR: 1.26e-05\nStep 1640/5000, Loss: 1.4163, LR: 1.24e-05\nStep 1680/5000, Loss: 1.4195, LR: 1.23e-05\nStep 1720/5000, Loss: 1.4157, LR: 1.21e-05\nStep 1760/5000, Loss: 1.4156, LR: 1.20e-05\nStep 1800/5000, Loss: 1.4151, LR: 1.18e-05\nStep 1840/5000, Loss: 1.4125, LR: 1.17e-05\nStep 1880/5000, Loss: 1.4128, LR: 1.16e-05\nStep 1920/5000, Loss: 1.4101, LR: 1.14e-05\nStep 1960/5000, Loss: 1.4084, LR: 1.13e-05\nStep 2000/5000, Loss: 1.4057, LR: 1.11e-05\nStep 2040/5000, Loss: 1.4068, LR: 1.10e-05\nStep 2080/5000, Loss: 1.4062, LR: 1.08e-05\nStep 2120/5000, Loss: 1.4025, LR: 1.07e-05\nStep 2160/5000, Loss: 1.4031, LR: 1.05e-05\nStep 2200/5000, Loss: 1.4055, LR: 1.04e-05\nStep 2240/5000, Loss: 1.4047, LR: 1.02e-05\nStep 2280/5000, Loss: 1.4044, LR: 1.01e-05\nStep 2320/5000, Loss: 1.4062, LR: 9.92e-06\nStep 2360/5000, Loss: 1.4082, LR: 9.77e-06\nStep 2400/5000, Loss: 1.4082, LR: 9.63e-06\nStep 2440/5000, Loss: 1.4080, LR: 9.48e-06\nStep 2480/5000, Loss: 1.4086, LR: 9.33e-06\nStep 2520/5000, Loss: 1.4070, LR: 9.18e-06\nStep 2560/5000, Loss: 1.4063, LR: 9.03e-06\nStep 2600/5000, Loss: 1.4057, LR: 8.89e-06\nStep 2640/5000, Loss: 1.4068, LR: 8.74e-06\nStep 2680/5000, Loss: 1.4064, LR: 8.59e-06\nStep 2720/5000, Loss: 1.4056, LR: 8.44e-06\nStep 2760/5000, Loss: 1.4055, LR: 8.29e-06\nStep 2800/5000, Loss: 1.4043, LR: 8.15e-06\nStep 2840/5000, Loss: 1.4040, LR: 8.00e-06\nStep 2880/5000, Loss: 1.4048, LR: 7.85e-06\nStep 2920/5000, Loss: 1.4055, LR: 7.70e-06\nStep 2960/5000, Loss: 1.4054, LR: 7.55e-06\nStep 3000/5000, Loss: 1.4060, LR: 7.41e-06\nStep 3040/5000, Loss: 1.4053, LR: 7.26e-06\nStep 3080/5000, Loss: 1.4034, LR: 7.11e-06\nStep 3120/5000, Loss: 1.4019, LR: 6.96e-06\nStep 3160/5000, Loss: 1.4019, LR: 6.81e-06\nStep 3200/5000, Loss: 1.4014, LR: 6.66e-06\nStep 3240/5000, Loss: 1.4010, LR: 6.52e-06\nStep 3280/5000, Loss: 1.3999, LR: 6.37e-06\nStep 3320/5000, Loss: 1.3996, LR: 6.22e-06\nStep 3360/5000, Loss: 1.3994, LR: 6.07e-06\nStep 3400/5000, Loss: 1.4014, LR: 5.92e-06\nStep 3440/5000, Loss: 1.4013, LR: 5.78e-06\nStep 3480/5000, Loss: 1.4010, LR: 5.63e-06\nStep 3520/5000, Loss: 1.4005, LR: 5.48e-06\nStep 3560/5000, Loss: 1.4009, LR: 5.33e-06\nStep 3600/5000, Loss: 1.4011, LR: 5.18e-06\nStep 3640/5000, Loss: 1.4013, LR: 5.04e-06\nStep 3680/5000, Loss: 1.4007, LR: 4.89e-06\nStep 3720/5000, Loss: 1.4014, LR: 4.74e-06\nStep 3760/5000, Loss: 1.4018, LR: 4.59e-06\nStep 3800/5000, Loss: 1.4020, LR: 4.44e-06\nStep 3840/5000, Loss: 1.4021, LR: 4.30e-06\nStep 3880/5000, Loss: 1.4015, LR: 4.15e-06\nStep 3920/5000, Loss: 1.4021, LR: 4.00e-06\nStep 3960/5000, Loss: 1.4028, LR: 3.85e-06\nStep 4000/5000, Loss: 1.4027, LR: 3.70e-06\nStep 4040/5000, Loss: 1.4017, LR: 3.55e-06\nStep 4080/5000, Loss: 1.4012, LR: 3.41e-06\nStep 4120/5000, Loss: 1.4020, LR: 3.26e-06\nStep 4160/5000, Loss: 1.4022, LR: 3.11e-06\nStep 4200/5000, Loss: 1.4012, LR: 2.96e-06\nStep 4240/5000, Loss: 1.4010, LR: 2.81e-06\nStep 4280/5000, Loss: 1.4018, LR: 2.67e-06\nStep 4320/5000, Loss: 1.4006, LR: 2.52e-06\nStep 4360/5000, Loss: 1.4005, LR: 2.37e-06\nStep 4400/5000, Loss: 1.4012, LR: 2.22e-06\nStep 4440/5000, Loss: 1.4025, LR: 2.07e-06\nStep 4480/5000, Loss: 1.4032, LR: 1.93e-06\nStep 4520/5000, Loss: 1.4029, LR: 1.78e-06\nStep 4560/5000, Loss: 1.4020, LR: 1.63e-06\nStep 4600/5000, Loss: 1.4014, LR: 1.48e-06\nStep 4640/5000, Loss: 1.4014, LR: 1.33e-06\nStep 4680/5000, Loss: 1.4023, LR: 1.18e-06\nStep 4720/5000, Loss: 1.4033, LR: 1.04e-06\nStep 4760/5000, Loss: 1.4020, LR: 8.89e-07\nStep 4800/5000, Loss: 1.4012, LR: 7.41e-07\nStep 4840/5000, Loss: 1.4003, LR: 5.92e-07\nStep 4880/5000, Loss: 1.4008, LR: 4.44e-07\nStep 4920/5000, Loss: 1.4013, LR: 2.96e-07\nStep 4960/5000, Loss: 1.4011, LR: 1.48e-07\nStep 5000/5000, Loss: 1.4004, LR: 0.00e+00\nTraining Time: 27 mins 9 seconds\nTraining Loss: 1.4004\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a6a5a1baabe4477b7bab41235b33f13"}},"metadata":{}},{"name":"stdout","text":"Training Time: 8 mins 18 seconds\nValidation Loss: 1.6062\nPerplexity: 4.98\nNew best model! Saved to ./qwen-vietnamese-wiki-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/870M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3f3dadd178c4bb29a792f60c37a0272"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Also saved to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU\nTraining state saved to ./qwen-vietnamese-wiki-finetuned!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"training_state.pt:   0%|          | 0.00/2.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6858b06e9691443a974eb039fb0ed516"}},"metadata":{}},{"name":"stdout","text":"Training state pushed to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# After training","metadata":{}},{"cell_type":"markdown","source":"## Test after training","metadata":{}},{"cell_type":"code","source":"test_prompts = [\n    \"Việt Nam là một quốc gia\",\n    \"Tiêu đề: Hà Nội\\n\\nNội dung:\",\n    \"Lịch sử Việt Nam bắt đầu từ\",\n    \"Văn hóa truyền thống của người Việt\",\n    \"Tiêu đề: Phở\\n\\nNội dung: Phở là\"\n]\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TESTING THE FINE-TUNED MODEL\")\nprint(\"=\" * 60)\n\nfor i, prompt in enumerate(test_prompts, 1):\n    print(f\"\\n--- Test {i} ---\")\n    print(f\"Prompt: {prompt}\")\n    print(\"-\" * 40)\n    \n    generated = generate_text(prompt, max_length=150, temperature=0.7)\n    print(f\"Generated: {generated}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T07:34:19.929849Z","iopub.execute_input":"2025-06-21T07:34:19.930302Z","iopub.status.idle":"2025-06-21T07:34:57.287775Z","shell.execute_reply.started":"2025-06-21T07:34:19.930239Z","shell.execute_reply":"2025-06-21T07:34:57.287154Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTESTING THE FINE-TUNED MODEL\n============================================================\n\n--- Test 1 ---\nPrompt: Việt Nam là một quốc gia\n----------------------------------------\nGenerated: Việt Nam là một quốc gia có tổng số 12 triệu dân. Dân số của Việt Nam là 11 triệu dân và tỷ lệ 50% của dân số là con trai, 60% của dân số là con gái, còn lại là con người. Huyện là đơn vị hành chính cơ bản.\nHuyện có dân số 300.000 dân và tỷ lệ dân số của huyện là 14%. Dân số của huyện là 78% của dân số tổng cộng toàn quốc có tỷ lệ dân số này là 90% thì năm nay có thể nói rằng huyện là một thành viên của nhóm các đơn vị hành chính cấp 3. Trả\n\n--- Test 2 ---\nPrompt: Tiêu đề: Hà Nội\n\nNội dung:\n----------------------------------------\nGenerated: Tiêu đề: Hà Nội\n\nNội dung: Hà Nội là một đô thị thuộc quận Hoa Kỳ, bang Tây Ban Nha. Nó có diện tích lãnh thổ 396 km2, dân số năm 1950 là 481.7 người và mật độ dân số đạt 2.360 người/km².\nDân số thời điểm 2010 (thời điểm này), Hà Nội có tỷ lệ dân số 53% biết đọc biết viết. Các khu vực chính đóng vai trò quan trọng trong sự phát triển của đô thị, nhất là các khu vực như sau: \n- Đô thị Hà Nội: Diện tích 396 km2\n\n--- Test 3 ---\nPrompt: Lịch sử Việt Nam bắt đầu từ\n----------------------------------------\nGenerated: Lịch sử Việt Nam bắt đầu từ khi người ta có biết đến về lịch sử lịch sử của con người. Trong thời đại hiện đại, việc học các ngành nghiên cứu văn hóa và lịch sử đã bắt đầu phát triển từ lâu nay với mục tiêu là xây dựng nền tảng văn hoá và kinh tế - xã hội toàn quốc. Hiện nay, những năm gần đây, với sự chuyển dịch về hướng nghiên cứu khoa học, học viện có thể được mở rộng, còn lại thì vẫn là một phần của quá trình giáo dục truyền thống. Câu chuyện của lịch sử Việt Nam bắt đầu từ khi con người biết biết đến lịch sử lịch sử của con người. Tại sao nói rằng lịch sử Việt Nam ngày\n\n--- Test 4 ---\nPrompt: Văn hóa truyền thống của người Việt\n----------------------------------------\nGenerated: Văn hóa truyền thống của người Việt Nam là gì và có vai trò trong việc bảo vệ văn hóa và sức khỏe tinh thần của thế hệ trẻ hiện nay\n\nNêu 5 nguyên nhân góp phần vào việc duy trì và phát tán các phong cách và giá trị văn hóa truyền thống của người Việt Nam\n\nDưới đây là 5 nguyên nhân nào cũng được liệt kê lên đây: 1. 2. 3. 4. 5. \n\nĐể tránh đưa ra những ý kiến thiếu thật, chúng ta cần tìm hiểu kỹ lưỡng và xem xét mọi yếu tố liên quan đến đề tài.\nGiới thiệu cho bài viết này về một chủ đề xã hội học (ví dụ: Tr\n\n--- Test 5 ---\nPrompt: Tiêu đề: Phở\n\nNội dung: Phở là\n----------------------------------------\nGenerated: Tiêu đề: Phở\n\nNội dung: Phở là một chi thực vật có hoa trong họ Măng tây. Chi này thuộc họ Hòa thảo. Chúng phân bố ở miền Tân bắc. \"Phở\" là tên của một loài thực vật có hoa thuộc họ Đậu. \"Phở\" là tên của một loài thực vật có hoa thuộc Họ Đậu.\nDanh pháp khoa học của \"Phở\" gồm: bộ ống, họ Đậu, Măng tây, Măng tây. \"Phở\" là một loài thuộc chi \"Phở\". \"Phở\" là một loài thực vật có hoa thuộc họ Đậu. \"Phở\" là một\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Save training log","metadata":{}},{"cell_type":"code","source":"# Save comprehensive training log\ntraining_log = {\n    'config': vars(config),\n    'model_info': {\n        'model_name': config.model_name,\n        'num_parameters': model.num_parameters(),\n        'dataset_name': config.dataset_name,\n        'train_samples': len(train_ds),\n        'valid_samples': len(valid_ds)\n    },\n    'training_results': {\n        'best_valid_loss': best_valid_loss,\n        'final_perplexity': training_history['valid_perplexities'][-1],\n        'total_epochs': config.num_train_epochs,\n        'total_steps': total_steps\n    },\n    'training_history': training_history,\n    'training_date': datetime.now().isoformat()\n}\n\nwith open(os.path.join(config.output_dir, 'training_log.json'), 'w', encoding='utf-8') as f:\n    json.dump(training_log, f, indent=2, ensure_ascii=False)\nprint(f\"\\nTraining log saved to {config.output_dir}/training_log.json\")\n\nif config.use_hf:\n    hf_api.upload_file(\n        path_or_fileobj=os.path.join(config.output_dir, 'training_log.json'),\n        path_in_repo=\"training_log.json\",\n        repo_id=config.hf_repo,\n        repo_type=\"model\",\n    )\nprint(f\"\\nTraining log pushed to repo {config.hf_repo}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T07:34:57.288643Z","iopub.execute_input":"2025-06-21T07:34:57.288918Z","iopub.status.idle":"2025-06-21T07:34:57.803473Z","shell.execute_reply.started":"2025-06-21T07:34:57.288895Z","shell.execute_reply":"2025-06-21T07:34:57.802831Z"}},"outputs":[{"name":"stdout","text":"\nTraining log saved to ./qwen-vietnamese-wiki-finetuned/training_log.json\n\nTraining log pushed to repo Quoc59/PARADIS-Qwen3_0.6B-10kWikiVi-1GPU\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Clean up","metadata":{}},{"cell_type":"code","source":"if config.use_wandb:\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T07:34:57.804220Z","iopub.execute_input":"2025-06-21T07:34:57.804466Z","iopub.status.idle":"2025-06-21T07:34:58.208585Z","shell.execute_reply.started":"2025-06-21T07:34:57.804449Z","shell.execute_reply":"2025-06-21T07:34:58.208029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>learning_rate</td><td>▂▂▃▄▇██▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>perplexity</td><td>█▂▁</td></tr><tr><td>train_loss</td><td>██▇▆▆▅▅▅▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_time (m)</td><td>▁▁▁</td></tr><tr><td>valid_loss</td><td>█▂▁</td></tr><tr><td>valid_time (m)</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>perplexity</td><td>4.98368</td></tr><tr><td>train_loss</td><td>1.40039</td></tr><tr><td>train_step</td><td>15000</td></tr><tr><td>train_time (m)</td><td>27</td></tr><tr><td>valid_loss</td><td>1.60617</td></tr><tr><td>valid_time (m)</td><td>8</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">1GPU</strong> at: <a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B/runs/j6f85ssx' target=\"_blank\">https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B/runs/j6f85ssx</a><br> View project at: <a href='https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B' target=\"_blank\">https://wandb.ai/tungnguyen19995969-hanoi-university-of-science-and-techn/PARADIS-Qwen3_0.6B</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250621_053948-j6f85ssx/logs</code>"},"metadata":{}}],"execution_count":31}]}